{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61358e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, UpSampling2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5eb3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075f7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "    #concat_axis = 3 # 3 o 1\n",
    "    concat_axis = 1 \n",
    "    #inputs = layers.Input(shape = (80, 120, 3))\n",
    "    inputs = layers.Input(shape = (3, 128, 144))\n",
    "    \n",
    "    #encoder\n",
    "    bn0 = BatchNormalization(axis=1)(inputs)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(bn0)\n",
    "    bn1 = BatchNormalization(axis=1)(conv1)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(bn1)\n",
    "    bn2 = BatchNormalization(axis=1)(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    bn3 = BatchNormalization(axis=1)(conv2)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(bn3)\n",
    "    bn4 = BatchNormalization(axis=1)(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(bn4)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    bn5 = BatchNormalization(axis=1)(conv3)\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn5)\n",
    "    bn6 = BatchNormalization(axis=1)(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(bn6)\n",
    "\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    bn7 = BatchNormalization(axis=1)(conv4)\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(bn7)\n",
    "    bn8 = BatchNormalization(axis=1)(conv4)\n",
    "    #pool4 = layers.MaxPooling2D(pool_size=(2, 3))(bn8)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(bn8)\n",
    "    \n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    bn9 = BatchNormalization(axis=1)(conv5)\n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(bn9)\n",
    "    bn10 = BatchNormalization(axis=1)(conv5)\n",
    "\n",
    "    ##decoder\n",
    "    #up_conv5 = layers.UpSampling2D(size=(2, 3))(bn10)\n",
    "    up_conv5 = layers.UpSampling2D(size=(2, 2))(bn10)\n",
    "    up6 = layers.concatenate([up_conv5, conv4], axis=concat_axis)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    bn11 = BatchNormalization(axis=1)(conv6)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(bn11)\n",
    "    bn12 = BatchNormalization(axis=1)(conv6)\n",
    "\n",
    "    up_conv6 = layers.UpSampling2D(size=(2, 2))(bn12)\n",
    "    up7 = layers.concatenate([up_conv6, conv3], axis=concat_axis)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    bn13 = BatchNormalization(axis=1)(conv7)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn13)\n",
    "    bn14 = BatchNormalization(axis=1)(conv7)\n",
    "\n",
    "    up_conv7 = layers.UpSampling2D(size=(2, 2))(bn14)\n",
    "    up8 = layers.concatenate([up_conv7, conv2], axis=concat_axis)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    bn15 = BatchNormalization(axis=1)(conv8)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(bn15)\n",
    "    bn16 = BatchNormalization(axis=1)(conv8)\n",
    "\n",
    "    up_conv8 = layers.UpSampling2D(size=(2, 2))(bn16)\n",
    "    up9 = layers.concatenate([up_conv8, conv1], axis=concat_axis)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    bn17 = BatchNormalization(axis=1)(conv9)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(bn17)\n",
    "    bn18 = BatchNormalization(axis=1)(conv9)\n",
    "\n",
    "    conv10 = layers.Conv2D(1, (1, 1))(bn18)\n",
    "    #bn19 = BatchNormalization(axis=1)(conv10)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mae', optimizer=sgd, metrics=['mse','acc'])\n",
    "    #model.compile(loss='mae', optimizer=Adam(lr=0.01), metrics=['mse'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28764555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel last\n",
    "def get_unet():\n",
    "    concat_axis = 3 # 3 o 1\n",
    "#    concat_axis = 1 \n",
    "    #inputs = layers.Input(shape = (80, 120, 3))\n",
    "    inputs = layers.Input(shape = (128, 144, 3))\n",
    "    \n",
    "    #encoder\n",
    "    bn0 = BatchNormalization(axis=3)(inputs)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(bn0)\n",
    "    bn1 = BatchNormalization(axis=3)(conv1)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(bn1)\n",
    "    bn2 = BatchNormalization(axis=3)(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    bn3 = BatchNormalization(axis=3)(conv2)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(bn3)\n",
    "    bn4 = BatchNormalization(axis=3)(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(bn4)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    bn5 = BatchNormalization(axis=3)(conv3)\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn5)\n",
    "    bn6 = BatchNormalization(axis=3)(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(bn6)\n",
    "\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    bn7 = BatchNormalization(axis=3)(conv4)\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(bn7)\n",
    "    bn8 = BatchNormalization(axis=3)(conv4)\n",
    "    #pool4 = layers.MaxPooling2D(pool_size=(2, 3))(bn8)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(bn8)\n",
    "    \n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    bn9 = BatchNormalization(axis=3)(conv5)\n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(bn9)\n",
    "    bn10 = BatchNormalization(axis=3)(conv5)\n",
    "\n",
    "    ##decoder\n",
    "    #up_conv5 = layers.UpSampling2D(size=(2, 3))(bn10)\n",
    "    up_conv5 = layers.UpSampling2D(size=(2, 2))(bn10)\n",
    "    up6 = layers.concatenate([up_conv5, conv4], axis=concat_axis)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    bn11 = BatchNormalization(axis=3)(conv6)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(bn11)\n",
    "    bn12 = BatchNormalization(axis=3)(conv6)\n",
    "\n",
    "    up_conv6 = layers.UpSampling2D(size=(2, 2))(bn12)\n",
    "    up7 = layers.concatenate([up_conv6, conv3], axis=concat_axis)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    bn13 = BatchNormalization(axis=3)(conv7)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn13)\n",
    "    bn14 = BatchNormalization(axis=3)(conv7)\n",
    "\n",
    "    up_conv7 = layers.UpSampling2D(size=(2, 2))(bn14)\n",
    "    up8 = layers.concatenate([up_conv7, conv2], axis=concat_axis)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    bn15 = BatchNormalization(axis=3)(conv8)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(bn15)\n",
    "    bn16 = BatchNormalization(axis=3)(conv8)\n",
    "\n",
    "    up_conv8 = layers.UpSampling2D(size=(2, 2))(bn16)\n",
    "    up9 = layers.concatenate([up_conv8, conv1], axis=concat_axis)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    bn17 = BatchNormalization(axis=3)(conv9)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(bn17)\n",
    "    bn18 = BatchNormalization(axis=3)(conv9)\n",
    "\n",
    "    conv10 = layers.Conv2D(1, (1, 1))(bn18)\n",
    "    #bn19 = BatchNormalization(axis=1)(conv10)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mae', optimizer=sgd, metrics=['mse','acc'])\n",
    "    #model.compile(loss='mae', optimizer=Adam(lr=0.01), metrics=['mse'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d2cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 144, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 144, 3)  12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 128, 144, 32) 896         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 144, 32) 128         conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 144, 32) 9248        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 144, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 72, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 72, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 72, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 72, 64)   36928       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 72, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 36, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 36, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 36, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 36, 128)  147584      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 36, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 18, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 18, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 18, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 18, 256)  590080      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 18, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 9, 256)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 9, 512)    1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 9, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 9, 512)    2359808     batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 9, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 16, 18, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 18, 768)  0           up_sampling2d[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 18, 256)  1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 18, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 18, 256)  590080      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 18, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 36, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 36, 384)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 36, 128)  442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 36, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 36, 128)  147584      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 36, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 72, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 72, 192)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 72, 64)   110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 72, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 72, 64)   36928       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 72, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 144, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 144, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 144, 32) 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 144, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 144, 32) 9248        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 144, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 144, 1)  33          batch_normalization_18[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,858,445\n",
      "Trainable params: 7,852,551\n",
      "Non-trainable params: 5,894\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff14c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13502, 3, 137, 157)\n",
      "(2893, 3, 137, 157)\n",
      "(13502, 137, 157)\n",
      "(2893, 137, 157)\n"
     ]
    }
   ],
   "source": [
    "## X:\n",
    "X_train = np.load(\"/opt/datos/dataset/gfs/X_train_3-7-9.npy\")\n",
    "X_val   = np.load(\"/opt/datos/dataset/gfs/X_val_3-7-9.npy\")\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "## Y:\n",
    "Y_train = np.load(\"/opt/datos/dataset/gfs/Y_train.npy\")\n",
    "Y_val   = np.load(\"/opt/datos/dataset/gfs/Y_val.npy\")\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6276a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13502, 3, 128, 144)\n",
      "(2893, 3, 128, 144)\n",
      "(13502, 128, 144)\n",
      "(2893, 128, 144)\n"
     ]
    }
   ],
   "source": [
    "# Recorte para obtener 128x144\n",
    "X_train = X_train[:, :, 0:128, 0:144]\n",
    "X_val = X_val[:, :, 0:128, 0:144]\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "Y_train = Y_train[:, 0:128, 0:144]\n",
    "Y_val = Y_val[:, 0:128, 0:144]\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8dd4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13502, 1, 128, 144)\n",
      "(2893, 1, 128, 144)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.expand_dims(Y_train, axis=1)\n",
    "Y_val = np.expand_dims(Y_val, axis=1)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7c56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (13502, 128, 144, 3)\n",
      "X_val: (2893, 128, 144, 3)\n",
      "Y_train: (13502, 128, 144, 1)\n",
      "Y_val: (2893, 128, 144, 1)\n"
     ]
    }
   ],
   "source": [
    "# Muevo el eje RGB al ultimo\n",
    "X_train = np.moveaxis(X_train, 1, 3)\n",
    "X_val = np.moveaxis(X_val, 1, 3)\n",
    "print(\"X_train: %s\" %str(X_train.shape))\n",
    "print(\"X_val: %s\" %str(X_val.shape))\n",
    "\n",
    "Y_train = np.moveaxis(Y_train, 1, 3)\n",
    "Y_val = np.moveaxis(Y_val, 1, 3)\n",
    "print(\"Y_train: %s\" %str(Y_train.shape))\n",
    "print(\"Y_val: %s\" %str(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224e54b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "422/422 [==============================] - 295s 573ms/step - loss: 0.5247 - mse: 3.7294 - acc: 0.6883 - val_loss: 0.3626 - val_mse: 2.2776 - val_acc: 0.8767\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.4327 - mse: 3.4197 - acc: 0.7043 - val_loss: 0.3528 - val_mse: 2.0387 - val_acc: 0.8675\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.4137 - mse: 3.1343 - acc: 0.7039 - val_loss: 0.3378 - val_mse: 1.8690 - val_acc: 0.8669\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.4046 - mse: 3.0410 - acc: 0.7042 - val_loss: 0.3323 - val_mse: 1.7447 - val_acc: 0.8640\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3955 - mse: 2.8937 - acc: 0.7031 - val_loss: 0.3325 - val_mse: 1.6955 - val_acc: 0.8632\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3887 - mse: 2.7352 - acc: 0.7038 - val_loss: 0.3240 - val_mse: 1.6214 - val_acc: 0.8656\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3788 - mse: 2.5902 - acc: 0.7055 - val_loss: 0.3304 - val_mse: 1.5745 - val_acc: 0.8557\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3732 - mse: 2.4823 - acc: 0.7051 - val_loss: 0.3244 - val_mse: 1.5090 - val_acc: 0.8588\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3663 - mse: 2.3748 - acc: 0.7063 - val_loss: 0.3159 - val_mse: 1.5218 - val_acc: 0.8623\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3643 - mse: 2.3344 - acc: 0.7005 - val_loss: 0.3188 - val_mse: 1.5189 - val_acc: 0.8644\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3570 - mse: 2.2339 - acc: 0.7051 - val_loss: 0.3222 - val_mse: 1.4834 - val_acc: 0.8615\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3521 - mse: 2.1874 - acc: 0.7069 - val_loss: 0.3222 - val_mse: 1.4659 - val_acc: 0.8586\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3481 - mse: 2.1292 - acc: 0.7048 - val_loss: 0.3250 - val_mse: 1.4530 - val_acc: 0.8620\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3440 - mse: 2.0574 - acc: 0.7029 - val_loss: 0.3145 - val_mse: 1.4690 - val_acc: 0.8672\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3418 - mse: 2.0227 - acc: 0.7062 - val_loss: 0.3166 - val_mse: 1.4704 - val_acc: 0.8634\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3393 - mse: 2.0181 - acc: 0.7059 - val_loss: 0.3173 - val_mse: 1.4350 - val_acc: 0.8615\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3330 - mse: 1.9254 - acc: 0.7053 - val_loss: 0.3125 - val_mse: 1.4252 - val_acc: 0.8618\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3307 - mse: 1.8920 - acc: 0.7052 - val_loss: 0.3130 - val_mse: 1.4392 - val_acc: 0.8624\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3272 - mse: 1.8358 - acc: 0.7049 - val_loss: 0.3157 - val_mse: 1.4174 - val_acc: 0.8586\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3263 - mse: 1.8304 - acc: 0.7061 - val_loss: 0.3209 - val_mse: 1.4199 - val_acc: 0.8569\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3234 - mse: 1.7927 - acc: 0.7056 - val_loss: 0.3193 - val_mse: 1.4209 - val_acc: 0.8609\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3185 - mse: 1.7405 - acc: 0.7085 - val_loss: 0.3275 - val_mse: 1.4619 - val_acc: 0.8570\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3180 - mse: 1.7501 - acc: 0.7065 - val_loss: 0.3193 - val_mse: 1.4115 - val_acc: 0.8574\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3138 - mse: 1.7094 - acc: 0.7077 - val_loss: 0.3229 - val_mse: 1.4337 - val_acc: 0.8585\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3124 - mse: 1.6743 - acc: 0.7069 - val_loss: 0.3224 - val_mse: 1.4147 - val_acc: 0.8637\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3098 - mse: 1.6473 - acc: 0.7072 - val_loss: 0.3144 - val_mse: 1.4104 - val_acc: 0.8605\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3069 - mse: 1.6192 - acc: 0.7064 - val_loss: 0.3188 - val_mse: 1.4150 - val_acc: 0.8593\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3081 - mse: 1.6225 - acc: 0.7074 - val_loss: 0.3222 - val_mse: 1.4295 - val_acc: 0.8570\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3026 - mse: 1.5608 - acc: 0.7085 - val_loss: 0.3290 - val_mse: 1.4299 - val_acc: 0.8602\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3040 - mse: 1.5802 - acc: 0.7074 - val_loss: 0.3171 - val_mse: 1.4058 - val_acc: 0.8628\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.3004 - mse: 1.5497 - acc: 0.7065 - val_loss: 0.3201 - val_mse: 1.4525 - val_acc: 0.8615\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2970 - mse: 1.5018 - acc: 0.7071 - val_loss: 0.3239 - val_mse: 1.4460 - val_acc: 0.8584\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2947 - mse: 1.4841 - acc: 0.7098 - val_loss: 0.3309 - val_mse: 1.4434 - val_acc: 0.8564\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2947 - mse: 1.4658 - acc: 0.7074 - val_loss: 0.3244 - val_mse: 1.4384 - val_acc: 0.8612\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2924 - mse: 1.4524 - acc: 0.7056 - val_loss: 0.3251 - val_mse: 1.4189 - val_acc: 0.8597\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2922 - mse: 1.4584 - acc: 0.7098 - val_loss: 0.3256 - val_mse: 1.4124 - val_acc: 0.8592\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2895 - mse: 1.4220 - acc: 0.7057 - val_loss: 0.3290 - val_mse: 1.4344 - val_acc: 0.8587\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2897 - mse: 1.4281 - acc: 0.7085 - val_loss: 0.3284 - val_mse: 1.4447 - val_acc: 0.8570\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2854 - mse: 1.3768 - acc: 0.7090 - val_loss: 0.3246 - val_mse: 1.4647 - val_acc: 0.8594\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2836 - mse: 1.3592 - acc: 0.7085 - val_loss: 0.3284 - val_mse: 1.4431 - val_acc: 0.8569\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2817 - mse: 1.3439 - acc: 0.7083 - val_loss: 0.3211 - val_mse: 1.4478 - val_acc: 0.8592\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2799 - mse: 1.3259 - acc: 0.7074 - val_loss: 0.3124 - val_mse: 1.4001 - val_acc: 0.8619\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2810 - mse: 1.3348 - acc: 0.7093 - val_loss: 0.3212 - val_mse: 1.4198 - val_acc: 0.8586\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2785 - mse: 1.3073 - acc: 0.7075 - val_loss: 0.3257 - val_mse: 1.4435 - val_acc: 0.8582\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2790 - mse: 1.3115 - acc: 0.7056 - val_loss: 0.3226 - val_mse: 1.4395 - val_acc: 0.8596\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2789 - mse: 1.3097 - acc: 0.7084 - val_loss: 0.3273 - val_mse: 1.4214 - val_acc: 0.8604\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2766 - mse: 1.2789 - acc: 0.7078 - val_loss: 0.3201 - val_mse: 1.4130 - val_acc: 0.8576\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2762 - mse: 1.2945 - acc: 0.7089 - val_loss: 0.3249 - val_mse: 1.4224 - val_acc: 0.8597\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2732 - mse: 1.2462 - acc: 0.7064 - val_loss: 0.3346 - val_mse: 1.4470 - val_acc: 0.8601\n",
      "Epoch 50/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2732 - mse: 1.2470 - acc: 0.7099 - val_loss: 0.3339 - val_mse: 1.4485 - val_acc: 0.8577\n",
      "Epoch 51/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2723 - mse: 1.2404 - acc: 0.7076 - val_loss: 0.3280 - val_mse: 1.4659 - val_acc: 0.8571\n",
      "Epoch 52/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2715 - mse: 1.2300 - acc: 0.7066 - val_loss: 0.3384 - val_mse: 1.4677 - val_acc: 0.8578\n",
      "Epoch 53/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2687 - mse: 1.2027 - acc: 0.7078 - val_loss: 0.3212 - val_mse: 1.4349 - val_acc: 0.8594\n",
      "Epoch 54/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2678 - mse: 1.1902 - acc: 0.7079 - val_loss: 0.3346 - val_mse: 1.5216 - val_acc: 0.8551\n",
      "Epoch 55/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2676 - mse: 1.1957 - acc: 0.7090 - val_loss: 0.3266 - val_mse: 1.4337 - val_acc: 0.8553\n",
      "Epoch 56/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2658 - mse: 1.1866 - acc: 0.7063 - val_loss: 0.3401 - val_mse: 1.4357 - val_acc: 0.8568\n",
      "Epoch 57/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2642 - mse: 1.1675 - acc: 0.7086 - val_loss: 0.3302 - val_mse: 1.4554 - val_acc: 0.8570\n",
      "Epoch 58/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2636 - mse: 1.1567 - acc: 0.7095 - val_loss: 0.3307 - val_mse: 1.4388 - val_acc: 0.8577\n",
      "Epoch 59/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2612 - mse: 1.1400 - acc: 0.7089 - val_loss: 0.3383 - val_mse: 1.5123 - val_acc: 0.8545\n",
      "Epoch 60/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2612 - mse: 1.1456 - acc: 0.7110 - val_loss: 0.3284 - val_mse: 1.4540 - val_acc: 0.8595\n",
      "Epoch 61/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2621 - mse: 1.1474 - acc: 0.7101 - val_loss: 0.3290 - val_mse: 1.4665 - val_acc: 0.8556\n",
      "Epoch 62/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2608 - mse: 1.1348 - acc: 0.7091 - val_loss: 0.3240 - val_mse: 1.4295 - val_acc: 0.8560\n",
      "Epoch 63/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2596 - mse: 1.1363 - acc: 0.7069 - val_loss: 0.3373 - val_mse: 1.4965 - val_acc: 0.8545\n",
      "Epoch 64/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2582 - mse: 1.1078 - acc: 0.7111 - val_loss: 0.3262 - val_mse: 1.4518 - val_acc: 0.8580\n",
      "Epoch 65/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2570 - mse: 1.0956 - acc: 0.7104 - val_loss: 0.3291 - val_mse: 1.4894 - val_acc: 0.8573\n",
      "Epoch 66/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2566 - mse: 1.0836 - acc: 0.7106 - val_loss: 0.3218 - val_mse: 1.4314 - val_acc: 0.8583\n",
      "Epoch 67/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2560 - mse: 1.0889 - acc: 0.7076 - val_loss: 0.3352 - val_mse: 1.4527 - val_acc: 0.8552\n",
      "Epoch 68/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2536 - mse: 1.0656 - acc: 0.7106 - val_loss: 0.3353 - val_mse: 1.4849 - val_acc: 0.8521\n",
      "Epoch 69/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2538 - mse: 1.0733 - acc: 0.7078 - val_loss: 0.3333 - val_mse: 1.4643 - val_acc: 0.8573\n",
      "Epoch 70/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2532 - mse: 1.0592 - acc: 0.7093 - val_loss: 0.3313 - val_mse: 1.4798 - val_acc: 0.8573\n",
      "Epoch 71/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2508 - mse: 1.0413 - acc: 0.7082 - val_loss: 0.3307 - val_mse: 1.4630 - val_acc: 0.8588\n",
      "Epoch 72/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2523 - mse: 1.0472 - acc: 0.7079 - val_loss: 0.3296 - val_mse: 1.4757 - val_acc: 0.8571\n",
      "Epoch 73/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2501 - mse: 1.0360 - acc: 0.7106 - val_loss: 0.3249 - val_mse: 1.4552 - val_acc: 0.8579\n",
      "Epoch 74/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2475 - mse: 1.0173 - acc: 0.7097 - val_loss: 0.3265 - val_mse: 1.4300 - val_acc: 0.8583\n",
      "Epoch 75/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2499 - mse: 1.0467 - acc: 0.7092 - val_loss: 0.3316 - val_mse: 1.4754 - val_acc: 0.8572\n",
      "Epoch 76/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2495 - mse: 1.0198 - acc: 0.7121 - val_loss: 0.3394 - val_mse: 1.4801 - val_acc: 0.8550\n",
      "Epoch 77/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2488 - mse: 1.0119 - acc: 0.7111 - val_loss: 0.3277 - val_mse: 1.4483 - val_acc: 0.8570\n",
      "Epoch 78/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2468 - mse: 1.0098 - acc: 0.7121 - val_loss: 0.3321 - val_mse: 1.4350 - val_acc: 0.8586\n",
      "Epoch 79/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2477 - mse: 1.0129 - acc: 0.7109 - val_loss: 0.3448 - val_mse: 1.4918 - val_acc: 0.8536\n",
      "Epoch 80/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2454 - mse: 0.9881 - acc: 0.7115 - val_loss: 0.3355 - val_mse: 1.4657 - val_acc: 0.8531\n",
      "Epoch 81/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2439 - mse: 0.9722 - acc: 0.7097 - val_loss: 0.3357 - val_mse: 1.4665 - val_acc: 0.8527\n",
      "Epoch 82/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2449 - mse: 0.9882 - acc: 0.7093 - val_loss: 0.3308 - val_mse: 1.5069 - val_acc: 0.8566\n",
      "Epoch 83/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2436 - mse: 0.9696 - acc: 0.7109 - val_loss: 0.3350 - val_mse: 1.4911 - val_acc: 0.8556\n",
      "Epoch 84/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2435 - mse: 0.9674 - acc: 0.7101 - val_loss: 0.3297 - val_mse: 1.4636 - val_acc: 0.8562\n",
      "Epoch 85/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2429 - mse: 0.9646 - acc: 0.7097 - val_loss: 0.3360 - val_mse: 1.5176 - val_acc: 0.8538\n",
      "Epoch 86/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2397 - mse: 0.9422 - acc: 0.7098 - val_loss: 0.3282 - val_mse: 1.4570 - val_acc: 0.8547\n",
      "Epoch 87/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2427 - mse: 0.9637 - acc: 0.7069 - val_loss: 0.3276 - val_mse: 1.4338 - val_acc: 0.8577\n",
      "Epoch 88/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2405 - mse: 0.9478 - acc: 0.7102 - val_loss: 0.3300 - val_mse: 1.4656 - val_acc: 0.8580\n",
      "Epoch 89/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2400 - mse: 0.9336 - acc: 0.7086 - val_loss: 0.3234 - val_mse: 1.4482 - val_acc: 0.8580\n",
      "Epoch 90/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2392 - mse: 0.9300 - acc: 0.7092 - val_loss: 0.3306 - val_mse: 1.4682 - val_acc: 0.8553\n",
      "Epoch 91/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2389 - mse: 0.9275 - acc: 0.7102 - val_loss: 0.3460 - val_mse: 1.5798 - val_acc: 0.8530\n",
      "Epoch 92/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2379 - mse: 0.9177 - acc: 0.7107 - val_loss: 0.3291 - val_mse: 1.4617 - val_acc: 0.8569\n",
      "Epoch 93/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2371 - mse: 0.9126 - acc: 0.7085 - val_loss: 0.3412 - val_mse: 1.4974 - val_acc: 0.8555\n",
      "Epoch 94/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2373 - mse: 0.9142 - acc: 0.7097 - val_loss: 0.3321 - val_mse: 1.4671 - val_acc: 0.8579\n",
      "Epoch 95/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2358 - mse: 0.8988 - acc: 0.7102 - val_loss: 0.3437 - val_mse: 1.4999 - val_acc: 0.8545\n",
      "Epoch 96/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2351 - mse: 0.8993 - acc: 0.7111 - val_loss: 0.3217 - val_mse: 1.4170 - val_acc: 0.8579\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2347 - mse: 0.8864 - acc: 0.7098 - val_loss: 0.3335 - val_mse: 1.4734 - val_acc: 0.8566\n",
      "Epoch 98/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2357 - mse: 0.8950 - acc: 0.7074 - val_loss: 0.3282 - val_mse: 1.4628 - val_acc: 0.8565\n",
      "Epoch 99/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2350 - mse: 0.8873 - acc: 0.7094 - val_loss: 0.3327 - val_mse: 1.4782 - val_acc: 0.8520\n",
      "Epoch 100/100\n",
      "422/422 [==============================] - 167s 395ms/step - loss: 0.2342 - mse: 0.8872 - acc: 0.7083 - val_loss: 0.3308 - val_mse: 1.5002 - val_acc: 0.8570\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=100, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b74821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/datos/entrenamientos/gfs/04', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7793995",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pickle.load( open( \"/opt/datos/entrenamientos/gfs/04\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c498db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ae0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Unet Dataset 2017-2021 ~\n",
      "val_loss: 0.3307879865169525\n",
      "loss: 0.23316173255443573\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"~ Unet Dataset 2017-2021 ~\")\n",
    "print(f\"val_loss: {history['val_loss'][-1]}\")\n",
    "print(f\"loss: {history['loss'][-1]}\")\n",
    "#print(history)\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Unet network training 1000-700-500 hPa')\n",
    "plt.ylabel('mean absolute error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4022342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/opt/datos/entrenamientos/gfs/04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007338d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
