{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5938bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Conv2D, UpSampling3D, MaxPooling3D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4016d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bc0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_LSTM():\n",
    "    #concat_axis = 3 # 3 o 1\n",
    "    concat_axis = 2 \n",
    "    #inputs = layers.Input(shape = (80, 120, 3))\n",
    "    inputs = layers.Input(shape = (4, 3, 128, 144))\n",
    "    \n",
    "    #encoder\n",
    "    bn0 = BatchNormalization(axis=2)(inputs)\n",
    "    conv1 = layers.ConvLSTM2D(32, (3, 3), activation='relu', padding='same',recurrent_activation = \"hard_sigmoid\",return_sequences=True,name='conv1_1')(bn0)\n",
    "    bn1 = BatchNormalization(axis=2)(conv1)\n",
    "    conv1 = layers.ConvLSTM2D(32, (3, 3), activation='relu', padding='same',recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn1)\n",
    "    bn2 = BatchNormalization(axis=2)(conv1)\n",
    "    pool1 = layers.MaxPooling3D(pool_size=(1,2, 2))(bn2)\n",
    "    conv2 = layers.ConvLSTM2D(64, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(pool1)\n",
    "    bn3 = BatchNormalization(axis=2)(conv2)\n",
    "    conv2 = layers.ConvLSTM2D(64, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn3)\n",
    "    bn4 = BatchNormalization(axis=2)(conv2)\n",
    "    pool2 = layers.MaxPooling3D(pool_size=(1, 2, 2))(bn4)\n",
    "\n",
    "    conv3 = layers.ConvLSTM2D(128, (3, 3), activation='relu', padding='same',recurrent_activation = \"hard_sigmoid\",return_sequences=True)(pool2)\n",
    "    bn5 = BatchNormalization(axis=2)(conv3)\n",
    "    conv3 = layers.ConvLSTM2D(128, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn5)\n",
    "    bn6 = BatchNormalization(axis=2)(conv3)\n",
    "    pool3 = layers.MaxPooling3D(pool_size=(1, 2, 2))(bn6)\n",
    "\n",
    "    conv4 = layers.ConvLSTM2D(256, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(pool3)\n",
    "    bn7 = BatchNormalization(axis=2)(conv4)\n",
    "    conv4 = layers.ConvLSTM2D(256, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn7)\n",
    "    bn8 = BatchNormalization(axis=2)(conv4)\n",
    "    #pool4 = layers.MaxPooling2D(pool_size=(2, 3))(bn8)\n",
    "    pool4 = layers.MaxPooling3D(pool_size=(1, 2, 2))(bn8)\n",
    "    \n",
    "    conv5 = layers.ConvLSTM2D(512, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(pool4)\n",
    "    bn9 = BatchNormalization(axis=2)(conv5)\n",
    "    conv5 = layers.ConvLSTM2D(512, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn9)\n",
    "    bn10 = BatchNormalization(axis=2)(conv5)\n",
    "\n",
    "    ##decoder\n",
    "    #up_conv5 = layers.UpSampling2D(size=(2, 3))(bn10)\n",
    "    up_conv5 = layers.UpSampling3D(size=(1,2, 2))(bn10)\n",
    "    up6 = layers.concatenate([up_conv5, conv4], axis=concat_axis)\n",
    "    conv6 = layers.ConvLSTM2D(256, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(up6)\n",
    "    bn11 = BatchNormalization(axis=2)(conv6)\n",
    "    conv6 = layers.ConvLSTM2D(256, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn11)\n",
    "    bn12 = BatchNormalization(axis=2)(conv6)\n",
    "\n",
    "    up_conv6 = layers.UpSampling3D(size=(1, 2, 2))(bn12)\n",
    "    up7 = layers.concatenate([up_conv6, conv3], axis=concat_axis)\n",
    "    conv7 = layers.ConvLSTM2D(128, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(up7)\n",
    "    bn13 = BatchNormalization(axis=2)(conv7)\n",
    "    conv7 = layers.ConvLSTM2D(128, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn13)\n",
    "    bn14 = BatchNormalization(axis=2)(conv7)\n",
    "\n",
    "    up_conv7 = layers.UpSampling3D(size=(1, 2, 2))(bn14)\n",
    "    up8 = layers.concatenate([up_conv7, conv2], axis=concat_axis)\n",
    "    conv8 = layers.ConvLSTM2D(64, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(up8)\n",
    "    bn15 = BatchNormalization(axis=2)(conv8)\n",
    "    conv8 = layers.ConvLSTM2D(64, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn15)\n",
    "    bn16 = BatchNormalization(axis=2)(conv8)\n",
    "\n",
    "    up_conv8 = layers.UpSampling3D(size=(1, 2, 2))(bn16)\n",
    "    up9 = layers.concatenate([up_conv8, conv1], axis=concat_axis)\n",
    "    conv9 = layers.ConvLSTM2D(32, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(up9)\n",
    "    bn17 = BatchNormalization(axis=2)(conv9)\n",
    "    conv9 = layers.ConvLSTM2D(32, (3, 3), activation='relu', padding='same', recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn17)\n",
    "    bn18 = BatchNormalization(axis=2)(conv9)\n",
    "\n",
    "    conv10 = layers.ConvLSTM2D(1, (1, 1), recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn18)\n",
    "    #bn19 = BatchNormalization(axis=2)(conv10)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mae', optimizer=sgd, metrics=['mse','acc'])\n",
    "    #model.compile(loss='mae', optimizer=Adam(lr=0.01), metrics=['mse'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affdd34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_LSTM2():\n",
    "    #concat_axis = 3 # 3 o 1\n",
    "    concat_axis = 2 \n",
    "    #inputs = layers.Input(shape = (80, 120, 3))\n",
    "    inputs = layers.Input(shape = (4, 3, 128, 144))\n",
    "    \n",
    "    #encoder\n",
    "    bn0 = BatchNormalization(axis=2)(inputs)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1')(bn0)\n",
    "    bn1 = BatchNormalization(axis=2)(conv1)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(bn1)\n",
    "    bn2 = BatchNormalization(axis=2)(conv1)\n",
    "    pool1 = layers.MaxPooling3D(pool_size=(1,2, 2))(bn2)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    bn3 = BatchNormalization(axis=2)(conv2)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(bn3)\n",
    "    bn4 = BatchNormalization(axis=2)(conv2)\n",
    "    pool2 = layers.MaxPooling3D(pool_size=(1,2, 2))(bn4)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    bn5 = BatchNormalization(axis=2)(conv3)\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn5)\n",
    "    bn6 = BatchNormalization(axis=2)(conv3)\n",
    "    pool3 = layers.MaxPooling3D(pool_size=(1,2, 2))(bn6)\n",
    "\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    bn7 = BatchNormalization(axis=2)(conv4)\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(bn7)\n",
    "    bn8 = BatchNormalization(axis=2)(conv4)\n",
    "    #pool4 = layers.MaxPooling2D(pool_size=(2, 3))(bn8)\n",
    "    pool4 = layers.MaxPooling3D(pool_size=(1,2, 2))(bn8)\n",
    "    \n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    bn9 = BatchNormalization(axis=2)(conv5)\n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(bn9)\n",
    "    bn10 = BatchNormalization(axis=2)(conv5)\n",
    "\n",
    "    ##decoder\n",
    "    #up_conv5 = layers.UpSampling2D(size=(2, 3))(bn10)\n",
    "    up_conv5 = layers.UpSampling3D(size=(1,2, 2))(bn10)\n",
    "    up6 = layers.concatenate([up_conv5, conv4], axis=concat_axis)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    bn11 = BatchNormalization(axis=2)(conv6)\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(bn11)\n",
    "    bn12 = BatchNormalization(axis=2)(conv6)\n",
    "\n",
    "    up_conv6 = layers.UpSampling3D(size=(1,2, 2))(bn12)\n",
    "    up7 = layers.concatenate([up_conv6, conv3], axis=concat_axis)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    bn13 = BatchNormalization(axis=2)(conv7)\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(bn13)\n",
    "    bn14 = BatchNormalization(axis=2)(conv7)\n",
    "\n",
    "    up_conv7 = layers.UpSampling3D(size=(1,2, 2))(bn14)\n",
    "    up8 = layers.concatenate([up_conv7, conv2], axis=concat_axis)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    bn15 = BatchNormalization(axis=2)(conv8)\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(bn15)\n",
    "    bn16 = BatchNormalization(axis=2)(conv8)\n",
    "\n",
    "    up_conv8 = layers.UpSampling3D(size=(1,2, 2))(bn16)\n",
    "    up9 = layers.concatenate([up_conv8, conv1], axis=concat_axis)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    bn17 = BatchNormalization(axis=2)(conv9)\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(bn17)\n",
    "    bn18 = BatchNormalization(axis=2)(conv9)\n",
    "\n",
    "    conv10 = layers.ConvLSTM2D(1, (1, 1), recurrent_activation = \"hard_sigmoid\",return_sequences=True)(bn18)\n",
    "    #bn19 = BatchNormalization(axis=2)(conv10)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mae', optimizer=sgd, metrics=['mse','acc'])\n",
    "    #model.compile(loss='mae', optimizer=Adam(lr=0.01), metrics=['mse'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55101af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 3, 128, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4, 3, 128, 14 12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 4, 32, 128, 1 896         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4, 32, 128, 1 128         conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 4, 32, 128, 1 9248        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4, 32, 128, 1 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 4, 32, 64, 72 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 64, 64, 72 18496       max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 64, 64, 72 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 64, 64, 72 36928       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 64, 64, 72 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 4, 64, 32, 36 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 128, 32, 3 73856       max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 4, 128, 32, 3 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 128, 32, 3 147584      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 128, 32, 3 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 4, 128, 16, 1 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 4, 256, 16, 1 295168      max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 256, 16, 1 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 256, 16, 1 590080      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 256, 16, 1 1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 4, 256, 8, 9) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 512, 8, 9) 1180160     max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 512, 8, 9) 2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 512, 8, 9) 2359808     batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 512, 8, 9) 2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)    (None, 4, 512, 16, 1 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 768, 16, 1 0           up_sampling3d[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 256, 16, 1 1769728     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 256, 16, 1 1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 256, 16, 1 590080      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 256, 16, 1 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 4, 256, 32, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 384, 32, 3 0           up_sampling3d_1[0][0]            \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 128, 32, 3 442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 128, 32, 3 512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 128, 32, 3 147584      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 128, 32, 3 512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 4, 128, 64, 7 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 192, 64, 7 0           up_sampling3d_2[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 64, 64, 72 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 64, 64, 72 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 64, 64, 72 36928       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 64, 64, 72 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 4, 64, 128, 1 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 96, 128, 1 0           up_sampling3d_3[0][0]            \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 32, 128, 1 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 32, 128, 1 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 32, 128, 1 9248        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 32, 128, 1 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)       (None, 4, 1, 128, 14 136         batch_normalization_18[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,858,548\n",
      "Trainable params: 7,852,654\n",
      "Non-trainable params: 5,894\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_unet_LSTM2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14bb0dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13502, 3, 137, 157)\n",
      "(2893, 3, 137, 157)\n",
      "(13502, 137, 157)\n",
      "(2893, 137, 157)\n"
     ]
    }
   ],
   "source": [
    "## X:\n",
    "X_train = np.load(\"/opt/datos/dataset/gfs/X_train_3-7-9.npy\")\n",
    "X_val   = np.load(\"/opt/datos/dataset/gfs/X_val_3-7-9.npy\")\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "## Y:\n",
    "Y_train = np.load(\"/opt/datos/dataset/gfs/Y_train.npy\")\n",
    "Y_val   = np.load(\"/opt/datos/dataset/gfs/Y_val.npy\")\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2248b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = np.reshape(X_train[0:13500],(3375,4,3,137,157))\n",
    "X_val_t   = np.reshape(X_val[0:2892],(723,4,3,137,157))\n",
    "X_train = None\n",
    "X_val = None\n",
    "\n",
    "Y_train_t = np.reshape(Y_train[0:13500],(3375,4,137,157))\n",
    "Y_val_t   = np.reshape(Y_val[0:2892],(723,4,137,157))\n",
    "Y_train = None\n",
    "Y_val = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b1b8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3375, 4, 3, 128, 144)\n",
      "(723, 4, 3, 128, 144)\n",
      "(3375, 4, 128, 144)\n",
      "(723, 4, 128, 144)\n"
     ]
    }
   ],
   "source": [
    "# Recorte para obtener 128x144\n",
    "X_train_t = X_train_t[:, :, :, 0:128, 0:144]\n",
    "X_val_t = X_val_t[:, :, :, 0:128, 0:144]\n",
    "print(X_train_t.shape)\n",
    "print(X_val_t.shape)\n",
    "\n",
    "Y_train_t = Y_train_t[:, :, 0:128, 0:144]\n",
    "Y_val_t = Y_val_t[:, :, 0:128, 0:144]\n",
    "print(Y_train_t.shape)\n",
    "print(Y_val_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956c3fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3375, 4, 1, 128, 144)\n",
      "(723, 4, 1, 128, 144)\n"
     ]
    }
   ],
   "source": [
    "Y_train_t = np.expand_dims(Y_train_t, axis=2)\n",
    "Y_val_t = np.expand_dims(Y_val_t, axis=2)\n",
    "\n",
    "print(Y_train_t.shape)\n",
    "print(Y_val_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "649e45d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "106/106 [==============================] - 397s 3s/step - loss: 0.5194 - mse: 3.6423 - acc: 0.0124 - val_loss: 0.3734 - val_mse: 2.4607 - val_acc: 0.0102\n",
      "Epoch 2/20\n",
      "106/106 [==============================] - 268s 3s/step - loss: 0.4401 - mse: 3.6534 - acc: 0.0354 - val_loss: 0.3702 - val_mse: 2.4426 - val_acc: 0.0124\n",
      "Epoch 3/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4367 - mse: 3.5945 - acc: 0.0423 - val_loss: 0.3674 - val_mse: 2.4196 - val_acc: 0.0306\n",
      "Epoch 4/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4293 - mse: 3.5235 - acc: 0.0462 - val_loss: 0.3622 - val_mse: 2.3282 - val_acc: 0.0544\n",
      "Epoch 5/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4261 - mse: 3.4321 - acc: 0.0474 - val_loss: 0.3568 - val_mse: 2.2673 - val_acc: 0.0583\n",
      "Epoch 6/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4313 - mse: 3.5733 - acc: 0.0503 - val_loss: 0.3553 - val_mse: 2.2084 - val_acc: 0.0613\n",
      "Epoch 7/20\n",
      "106/106 [==============================] - 268s 3s/step - loss: 0.4272 - mse: 3.4643 - acc: 0.0521 - val_loss: 0.3534 - val_mse: 2.2024 - val_acc: 0.0650\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4210 - mse: 3.4035 - acc: 0.0563 - val_loss: 0.3555 - val_mse: 2.1854 - val_acc: 0.0617\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4246 - mse: 3.4240 - acc: 0.0555 - val_loss: 0.3520 - val_mse: 2.1898 - val_acc: 0.0680\n",
      "Epoch 10/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4225 - mse: 3.4178 - acc: 0.0579 - val_loss: 0.3539 - val_mse: 2.1695 - val_acc: 0.0637\n",
      "Epoch 11/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4186 - mse: 3.3601 - acc: 0.0603 - val_loss: 0.3528 - val_mse: 2.1713 - val_acc: 0.0775\n",
      "Epoch 12/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4234 - mse: 3.4139 - acc: 0.0632 - val_loss: 0.3515 - val_mse: 2.1637 - val_acc: 0.0709\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4246 - mse: 3.4954 - acc: 0.0638 - val_loss: 0.3523 - val_mse: 2.1527 - val_acc: 0.0811\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4165 - mse: 3.4065 - acc: 0.0662 - val_loss: 0.3526 - val_mse: 2.1503 - val_acc: 0.0852\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4183 - mse: 3.4242 - acc: 0.0689 - val_loss: 0.3515 - val_mse: 2.1426 - val_acc: 0.0817\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4244 - mse: 3.4797 - acc: 0.0697 - val_loss: 0.3501 - val_mse: 2.1501 - val_acc: 0.0918\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4149 - mse: 3.3579 - acc: 0.0714 - val_loss: 0.3495 - val_mse: 2.1503 - val_acc: 0.0892\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4097 - mse: 3.3395 - acc: 0.0744 - val_loss: 0.3487 - val_mse: 2.1488 - val_acc: 0.0990\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4140 - mse: 3.3955 - acc: 0.0744 - val_loss: 0.3525 - val_mse: 2.1430 - val_acc: 0.0937\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 267s 3s/step - loss: 0.4046 - mse: 3.2402 - acc: 0.0788 - val_loss: 0.3527 - val_mse: 2.1327 - val_acc: 0.0969\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_t, Y_train_t, epochs=20, verbose=1, validation_data=(X_val_t, Y_val_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/datos/entrenamientos/gfs/08', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f168bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pickle.load( open( \"/opt/datos/entrenamientos/gfs/08\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efaa010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~ Unet Dataset GFS 2015-2021 ~\")\n",
    "print(f\"val_loss: {history['val_loss'][-1]}\")\n",
    "print(f\"loss: {history['loss'][-1]}\")\n",
    "#print(history)\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Unet network training 1000-700-500 hPa')\n",
    "plt.ylabel('mean absolute error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/opt/datos/entrenamientos/gfs/08.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu2",
   "language": "python",
   "name": "tf-gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
